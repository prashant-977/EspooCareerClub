{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Scrape Web pages for particular title"
      ],
      "metadata": {
        "id": "z2EgXPrHVjLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "Ym4mjXeGd0ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os\n",
        "from llama_index.core import GPTVectorStoreIndex, SimpleDirectoryReader, ListIndex, Document\n",
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "openai_api_key=userdata.get('openai_api_key');\n",
        "##load_dotenv()\n",
        "##openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "IcRDGQ_SIjdt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_job(job_title):\n",
        "    url = f\"https://www.jobly.fi/tyopaikat?search={job_title}\" # Construct the search URL\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\") # Parse the HTML content\n",
        "    job_listings = soup.find_all(\"a\", class_=\"recruiter-job-link\") # Example selector: Replace with the actual class or id of the job listing container.\n",
        "\n",
        "    job_links = [listing['href'] for listing in job_listings]\n",
        "    top3_jobs=job_links[::2][:3]\n",
        "    #print(top3_jobs)\n",
        "    return top3_jobs\n"
      ],
      "metadata": {
        "id": "kJI_ixRLHOzF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_title=\"Data Scientist\"\n",
        "top3_jobs=scrape_job(job_title)\n",
        "top3_jobs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i_iDytGM801",
        "outputId": "4e575002-ea55-4de9-811d-744597a5c64e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://www.jobly.fi/tyopaikka/data-scientist-2229094',\n",
              " 'https://www.jobly.fi/tyopaikka/data-scientist-2227309',\n",
              " 'https://www.jobly.fi/tyopaikka/senior-scientist-background-farm-animal-genetics-2220729']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def job_description(scrape_result):\n",
        "    dic = {}\n",
        "    for i, link in enumerate(top3_jobs):\n",
        "      response = requests.get(link)\n",
        "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "      job_description_element = soup.find(\"div\", class_=\"l-main\")\n",
        "      job_description = job_description_element.get_text(strip=True)\n",
        "      job_description = job_description_element.get_text(strip=True)\n",
        "      text = \"Hae paikkaaTallenna työpaikka\"\n",
        "      first_occurrence = job_description.find(text)\n",
        "      second_occurrence = job_description.find(text, first_occurrence + 1)\n",
        "      extracted_text = job_description[first_occurrence+len(text):second_occurrence]\n",
        "\n",
        "      dic[i] = extracted_text\n",
        "    return dic"
      ],
      "metadata": {
        "id": "S-4b2CBSH7bw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_3jobs = job_description(top3_jobs)"
      ],
      "metadata": {
        "id": "rs3wA0IXS-LD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If the text is in Finnish, then translate it to English"
      ],
      "metadata": {
        "id": "_c55SUgtVqVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install python-dotenv"
      ],
      "metadata": {
        "id": "3aAevdJvwf_e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search(query):\n",
        "    insights = {}\n",
        "    for item, summary in summary_3jobs.items():\n",
        "      # Create a document object\n",
        "      documents = [Document(text=summary)]\n",
        "      index = GPTVectorStoreIndex.from_documents(documents)\n",
        "      # Get a QueryEngine object from the index\n",
        "      query_engine = index.as_query_engine()\n",
        "      # Use the QueryEngine to query the index\n",
        "      response = query_engine.query(query)\n",
        "      insights[item] = response.response\n",
        "    return insights\n"
      ],
      "metadata": {
        "id": "AREpbhKEqaM0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Describe in 5 paragraphs: the job role/key responsibilities, the qualifications needed for the job and the key skills required for the job (both technical and soft skills), the domain and the seniority level. \"\n",
        "result=semantic_search(prompt)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxlW3k1UE5LM",
        "outputId": "4974f886-3590-44fa-cce8-3734381a50a5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'The job role entails working as a Data Scientist at Wärtsilä Voyage, focusing on the global Vessel Traffic Services (VTS) and Port Management Information Systems (PMIS) product lines. The key responsibilities include conceptualizing and specifying solution requirements in collaboration with business stakeholders, formalizing tasks, researching different approaches, designing and developing machine learning applications and algorithms, and building and optimizing machine learning pipelines. The role involves utilizing data from various sources to develop AI services that enhance safety, decarbonization, and operational efficiency in the maritime industry.\\n\\nTo qualify for the position, candidates should have a strong mathematical background in statistics and understanding of classical machine learning algorithms. Proficiency in software development using Python, familiarity with machine learning stack (NumPy, Pandas, Scikit-Learn, Pytorch), and web application stack (Fastapi/Flask) are essential. Additionally, experience with geospatial data, data engineering, and Azure cloud services is advantageous. Candidates with experience in the maritime industry, particularly in port operations or maritime logistics, and knowledge of supply chain and logistics practices are preferred.\\n\\nThe key skills required for the job encompass a blend of technical expertise and soft skills. Technical skills include proficiency in machine learning algorithms, software development in Python, and familiarity with relevant tools and technologies like NumPy, Pandas, Scikit-Learn, Pytorch, Fastapi/Flask, and Azure cloud services. Strong problem-solving abilities, the capacity to communicate abstract concepts to technical and non-technical stakeholders, and experience in the maritime industry are valuable soft skills for this role.\\n\\nThe domain of this job role is focused on the maritime industry, specifically Vessel Traffic Services (VTS) and Port Management Information Systems (PMIS). The position requires a deep understanding of maritime operations, port logistics, and supply chain practices. The role involves leveraging data from navigation, port schedules, weather, and other sources to develop AI services that enhance safety, decarbonization, and operational efficiency in the maritime sector.\\n\\nIn terms of seniority level, the position of Data Scientist at Wärtsilä Voyage appears to be at an intermediate to senior level. The job requires a combination of technical expertise, industry knowledge, and the ability to collaborate with business stakeholders to drive innovation in technology and services within the maritime industry. The role involves significant responsibilities in developing machine learning applications, optimizing pipelines, and contributing to the transformation towards a cleaner, more sustainable future in the marine and energy sectors.',\n",
              " 1: \"The job role entails supporting the implementation of the Data & AI strategy by creating, implementing, and maintaining AI solutions in collaboration with stakeholders across various business domains. This involves working with data engineers to manage data ingestion and migration, building and testing data models, deploying ML models in production, and supporting knowledge building across the organization. The role also includes ensuring compliance with the EU AI Act and driving the citizen community within the company.\\n\\nQualifications for the job include a master's degree in AI, statistics, computer science, or engineering, along with a minimum of 5 years of experience in data science projects. Experience in developing statistical and machine learning solutions for business problems, particularly in the context of manufacturing processes, is essential. Familiarity with relational databases, SQL-like query languages, cloud technologies like MS Azure, and tools such as Databricks is required. Knowledge of non-relational database technology and distributed computing is beneficial.\\n\\nKey technical skills required for the job include proficiency in developing statistical and machine learning solutions, experience with data ingestion and migration, and knowledge of cloud technologies for AI solution delivery. Soft skills such as effective communication with business stakeholders, collaboration with cross-functional teams, and the ability to drive knowledge sharing initiatives are crucial. The role demands a proactive approach to problem-solving, attention to detail in data analysis, and the ability to translate complex technical concepts into actionable insights for stakeholders.\\n\\nThe domain of the job role is within Data & Analytics, specifically focusing on implementing AI solutions to address process challenges in areas like plant operations, R&D, sales, and workplace productivity. The seniority level of the position is at an experienced level, requiring a minimum of 5 years of relevant working experience in data science projects. The role involves working closely with stakeholders, data engineers, and cloud experts to deliver AI solutions that drive business value and ensure compliance with regulations.\\n\\nIn summary, the job role involves leveraging data and AI technologies to address business challenges across different domains within the organization. The qualifications needed include a master's degree in a relevant field and substantial experience in data science projects, particularly in manufacturing processes. Key technical skills encompass proficiency in developing data models, deploying ML solutions, and working with cloud technologies, while essential soft skills include effective communication, collaboration, and a proactive problem-solving approach. The domain of the role is Data & Analytics, and the seniority level is at an experienced level, requiring a solid foundation in data science and AI technologies.\",\n",
              " 2: \"The job role of the Senior Scientist at NordGen Farm Animals involves leading and participating in projects related to the conservation and sustainable use of farm animal genetic resources. The key responsibilities include strengthening the scientific team's capacity to achieve NordGen's strategic goals, leading research projects, facilitating networks, giving lectures, and communicating with stakeholders. The Senior Scientist will also be responsible for identifying new project opportunities to enhance conservation efforts and promoting Nordic animal genetic resources.\\n\\nQualifications required for the job include a Ph.D. in animal genetics or related fields, relevant working experience in research, breeding, or conservation, successful project planning and management experience, a high number of published scientific articles, and experience in international research cooperation. Fluency in one of the Scandinavian languages and English is essential. Additional merits include experience in genomics data analysis, database utilization, a wide network of collaboration partners, and Nordic collaboration experience.\\n\\nThe key skills required for the job encompass both technical and soft skills. Technical skills include expertise in animal genetics, research methodologies, project management, and data analysis in genomics. Soft skills consist of being a team player, working independently, innovative thinking, adaptability to new challenges, collaboration with diverse organizations, and quick decision-making abilities. The Senior Scientist should also possess excellent communication skills to engage with stakeholders effectively.\\n\\nThe domain of this job is farm animal genetics, conservation, and sustainable use of genetic resources. The Senior Scientist will be working within the field of animal genetics, focusing on the conservation and utilization of Nordic farm animal genetic resources. The role involves contributing to the scientific advancements in the field and promoting sustainable practices in farm animal breeding and conservation efforts.\\n\\nThis position is at a senior level, requiring a Ph.D. and significant experience in research, breeding, or conservation. The Senior Scientist will be leading projects, consulting on conservation strategies, and engaging with stakeholders at national and international levels. The role demands a high level of expertise in the domain of farm animal genetics and a proactive approach to driving sustainable conservation initiatives within the Nordic countries and beyond.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### get_insights(result)"
      ],
      "metadata": {
        "id": "KpMyDZlHIPRT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specify the domain / field of industry"
      ],
      "metadata": {
        "id": "qYxe3_RcWKgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get all the seniority level skillsets required"
      ],
      "metadata": {
        "id": "Xfg3D9vcVudx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jfKwgZkgEoMd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarize the task and skillset"
      ],
      "metadata": {
        "id": "B3z7tVYrV1TU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1TBlvI7Esog"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Highlight the top keywords / skillsets"
      ],
      "metadata": {
        "id": "euvCPFCMV9It"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DknJ1jniWAEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What are the other keywords that you might search for your similar positions"
      ],
      "metadata": {
        "id": "LvPqsurnLPqo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXtDLP0LLVgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report the skills missing and visualize in Venn diagram, bubble diagram etc"
      ],
      "metadata": {
        "id": "1F2KQzmkWAlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WW2lIXQQWITH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Suggest how to upskill based on current market"
      ],
      "metadata": {
        "id": "CyGyXl-PXTJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NVqwj7XgXYlu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}